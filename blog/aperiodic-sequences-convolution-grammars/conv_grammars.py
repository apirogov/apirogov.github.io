"""Exploration of convolution grammars."""
# Copyright (C) 2023 Anton Pirogov, licensed under the MIT license
import re
from typing import Optional
from functools import partial
import itertools
from math import lcm

# ----
# Example grammars:

g1 = {"S": "0S1"}
g2 = {"S": "01S"}
g3 = {"S": "0S1SS"}
g4 = {"S": "1S0S"}

g12 = {"S": "0A1", "A": "01S"}
g11 = {"S": "0A1", "A": "0S1"}
g112 = {"S": "0A1", "A": "0B1", "B": "01S"}

# ----

_non_terminal_sym = re.compile("[^0-9a-z]")

def nonterminal_count(pat: str, sym: Optional[str] = None):
    sym = _infer_pat_sym(pat, sym)
    cnt = 0
    for letter in pat:
        if re.match(_non_terminal_sym, letter):
            cnt += 1
    return cnt

def _infer_pat_sym(pat: str, sym: Optional[str] = None) -> str:
    """Given a pattern `pat`, return the first non-terminal that can be found.

    If `sym` is passed, just returns sym (i.e. skip search).
    """
    return sym if sym else re.search(_non_terminal_sym, pat)[0]

def _infer_grammar_cycle(grammar):
    """Given a strictly cyclic grammar, infer the periodic convolution sequence."""
    curr = grammar["S"]
    seq = ["S"]
    while sym := _infer_pat_sym(grammar[seq[-1]], None):
        if sym == "S":
            break
        seq.append(sym)
    return ''.join(seq)

# ----

def conv(p1: str, p2: str, sym: Optional[str]=None) -> str:
    """Convolve two patterns `p1` and `p2` to a new pattern.

    If no non-terminal `sym` is passed, will try to infer it.
    """
    sym = _infer_pat_sym(p1, sym)
    num_syms = p1.count(sym)
    assert num_syms != 0, f"{sym} does not appear in {p1}!"

    l = lcm(num_syms, len(p2))
    n, m = l // num_syms, l // len(p2)
    s1 =iter(n * p1)
    s2 =iter(m * p2)
    return ''.join([c if c != sym else next(s2) for c in iter(s1)])

def convn(n: int, pat: str, sym: Optional[str]=None) -> str:
    """Convolve pattern `pat` with itself `n` times.

    If no non-terminal `sym` is passed, will try to infer it.
    """
    curr = sym = _infer_pat_sym(pat, sym)
    for i in range(n):
        curr = conv(curr, pat, sym)
    return curr

# ----

def grow(grammar, conv_seq=None, depth=0):
    """Convolve a singleton pattern or strictly cyclic grammar into an infinite word.

    Returns generator returning tuples (sym, depth), where sym is the final terminal
    symbol and depth is the number of convolution steps until this symbol stabilized.
    """
    if isinstance(grammar, str):
        grammar = {_infer_pat_sym(grammar, None): grammar}
    if not conv_seq:
        conv_seq = itertools.cycle(conv_seq or _infer_grammar_cycle(grammar))

    sym = next(conv_seq)
    rest = grow(grammar, conv_seq, depth=depth+1)  # recursive lazy generator
    pat = grammar[sym]
    nxt_sym = _infer_pat_sym(pat, None)
    yield from ((c, depth) if c != nxt_sym else next(rest) for c in itertools.cycle(pat))

def sample(word, n: int = 100):
    """Sample a finite prefix of a word generated by a convolution grammar."""
    return ''.join(map(lambda x: x[0], itertools.islice(word, n)))


def depths(word, n: int = 100):
    """Sample stabilization depths for symbols of a word generated by a convolution grammar.

    Depth 0 means the symbol was terminal already in the first pattern,
    depth 1 means the symbol was substituted by a terminal by the first convolution, etc.
    """
    return list(map(lambda x: x[1], itertools.islice(word, n)))

# ----

def subseq(word, d: int = 0):
    """Return a subsequence of given word at depth d."""
    return filter(lambda x: x[1] >= d, word) if d else word

def subseqs(seedword, max_depth=0):
    return [ subseq(grow(seedword), d) for d in range(max_depth+1) ]

def sample_seqs(grammar, *, max_depth=0, sample_length=100):
    max_depth = max_depth or len(grammar)+1
    seqs = subseqs(grammar, max_depth)
    return list(map(lambda x: sample(x, sample_length), seqs))

def diff(w1: str, w2: str):
    """Given two words, return sequence to pretty-print positions at which they differ."""
    return "".join(map(lambda x: " " if x[0]==x[1] else "x", zip(w1, w2)))

def compare(*ws: str):
    """Print a number of samples, showing differences between adjacent words."""
    print(ws[0])
    for i in range(1, len(ws)):
        print(diff(ws[i-1], ws[i]), ws[i], sep="\n")

# ----

def singleton_patterns(*,
    min_length: int = 3,
    max_length: int = 8,
    terminals: str = "01",
    nonterminals="S"
):
    """Generate all non-trivial singleton patterns over up to some length.

    Returns patterns that start with a terminal (i.e. valid)
    and which have >=2 distinct terminals and >=1 non-terminal (i.e. non-trivial).
    """
    assert min_length > 0
    ts = set(terminals)
    assert not ts.intersection(set(nonterminals))
    for i in range(min_length, max_length+1):
        yield from filter(
            lambda p: re.search(_non_terminal_sym, p) and len(set(p).intersection(ts))>1,
            map(''.join,
                itertools.product(
                    terminals,
                    *itertools.repeat(nonterminals+terminals, i-1)
                )
            )
        )

def detect_period(word, max_period: int = 100) -> Optional[str]:
    sample_len = max_period ** 2
    w = sample(word, sample_len)
    for i in range(1, max_period+1):
        first = w[:i]
        different = False
        for k in range(1, sample_len//i):
            if first != w[k*i:(k+1)*i]:
                different = True  # counterexample for period i found
                continue
        if not different:
            return first  # looks like a word with period of i
    return None  # no period detected

# ----

def segments(w, n: int = 1, *, seg_map=None):
    """Collect segments of length n, in first appearance order.

    If n is not passed, uses n=1, which normalizes the alphabet.

    Keyword argument seg_map can be a dict to be filled
    with new symbols representing the segments.
    If not passed, the mapping will not be externally available.
    """
    wgen = iter(w)  # ensure it is an iterator
    # use provided dict for mapping or create new one
    seg_map = seg_map if seg_map is not None else {}

    while True:
        # get next segment
        seg = tuple(itertools.islice(wgen, n))
        if not seg:
            break  # reached the end

        if isinstance(seg[0], str):
            seg = "".join(seg)  # concat if input is seq. of strings

        val = seg_map.get(seg)  # try to retrieve assigned symbol
        if val is None:  # must assign new symbol
            l = len(seg)
            if l == n:  # unknown full segment -> give it next free number
                val = len(seg_map)
            else:  # last segment, incomplete length -> mark with -1
                val = -1
            seg_map[seg] = val

        # return symbol for current segment according to segment map
        yield val


def infer_kl_uniform_morphic(cg, k: int, l: int, *, sample_length: int = 2000):
    g_map = {}
    if isinstance(cg, dict):
        gen = segments(map(lambda x: x[0], grow(cg)), l, seg_map=g_map)
    else:
        gen = iter(cg)

    f_map = {}
    gen2 = segments(gen, k, seg_map=f_map)

    f_map_ctl = {}
    gen3 = segments(gen2, k, seg_map=f_map_ctl)

    # force lazy generators by retrieving a sample (will fill the maps)
    w = tuple(itertools.islice(gen3, sample_length))

    if f_map != f_map_ctl:
        # word generated by cg appears not result from g(f^infty(0))
        return None

    f = {v: k for k,v in f_map.items()}
    g = {v: k for k,v in g_map.items()}
    return (f, g)


def infer_uniform_morphic(cg, mx_l: int = 0, mx_k: int = 0, *, sample_length: int = 2000):
    """Given a singleton convolution grammar, try inferring (k,l)-uniform mapping pair."""
    assert len(cg)==1
    pat = next(iter(cg.values()))
    max_l = mx_l or len(pat)
    max_k = mx_k or 12

    for j in range(2, max_k+1):
        for i in range(1, max_l+1):
            print(j, i)
            infer_kl_uniform_morphic(cg, j, i, sample_length=sample_length)

# ----

def check_singleton_grammars(min_len: int = 3, max_len: int = 8, max_period: int = 100):
    cnt, per, mor = 0, 0, 0
    for pat in singleton_patterns(min_length=min_len, max_length=max_len):
        if pat[0] == "1":
            continue  # optimization: w.l.o.g. test only patterns starting with 0

        length = len(pat)
        nterms = nonterminal_count(pat)
        print(pat, length, nterms)

        cnt += 1
        g = {"S": pat}
        if period := detect_period(grow(g), max_period=max_period):
            print(pat, f"looks periodic (period {len(period)}): {period}")
            per += 1
            mor += 1
            continue
        if length % nterms == 0:  # non-term. count is divisor of pat. length
            k, l = length//nterms, nterms  # expected parameters st. morphic map exists
            if mmap := infer_kl_uniform_morphic(g, k, l):
                assert len(mmap[0]) == len(mmap[1]), "f,g have not same alphabet size!"
                s = len(mmap[0])
                print(mmap)
                print(f"looks ({k},{l})-uniform morphic with alphabet size {s}")
                mor += 1
            else:
                raise RuntimeError("(k,l)-uniform morphic conjecture failed!")

    print("----", "Summary:", sep="\n")
    print(f"\t{per}/{cnt} of the patterns looked periodic.")
    print(f"\t{mor}/{cnt} of the patterns looked uniform morphic.")
